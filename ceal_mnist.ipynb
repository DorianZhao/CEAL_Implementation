{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain mnist dataset\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), target_transform=None, download=False)\n",
    "mnist_test = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor(), target_transform=None, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataloader of MNIST\n",
    "dl_train = torch.utils.data.DataLoader(mnist_train)\n",
    "dl_test = torch.utils.data.DataLoader(mnist_test)\n",
    "\n",
    "#y_train = (dl_train.dataset.targets).to(dtype=torch.long)\n",
    "#y_test = (dl_test.dataset.targets).to(dtype=torch.long)\n",
    "\n",
    "#tensor_train = (dl_train.dataset.data).to(dtype=torch.float32)\n",
    "#tensor_test = (dl_test.dataset.data).to(dtype=torch.float32)\n",
    "\n",
    "#x_train = tensor_train.reshape(tensor_train.size(0),-1)\n",
    "#x_train = x_train/255\n",
    "#x_test = tensor_test.reshape(tensor_test.size(0),-1)\n",
    "#x_test = x_test/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncertainty Sample Selection Criterias\n",
    "\n",
    "#Least confidence criteria\n",
    "#Return: indices of k selected samples, indices+prediction+lc value of k selected samples\n",
    "#prediction: batch_size x class_size\n",
    "def least_confidence(prediction,k):\n",
    "    lc_value, lc_class = np.max(prediction, axis=1), np.argmax(prediction, axis=1)\n",
    "    indices = list(range(len(prediction)))\n",
    "    lc_i = np.column_stack((indices, lc_class, lc_value))\n",
    "    # sort lc_i in ascending order\n",
    "    lc_i = lc_i[lc_i[:, -1].argsort()]\n",
    "    return lc_i[:k, 0].astype(np.int32), lc_i[:k]\n",
    "\n",
    "#Margin sampling criteria\n",
    "#Return: indices of k selected samples, indices+prediction+lc value of k selected samples\n",
    "def margin_sampling(prediction, k):\n",
    "     # Sort pred_prob to get j1 and j2\n",
    "    size = len(prediction)\n",
    "    margin = np.diff(np.abs(np.sort(prediction, axis=1)[:, ::-1][:, :2]))\n",
    "    pred_class = np.argmax(prediction, axis=1)\n",
    "    ms_i = np.column_stack((list(range(size)), pred_class, margin))\n",
    "\n",
    "    # sort ms_i in ascending order according to margin\n",
    "    ms_i = ms_i[ms_i[:, 2].argsort()]\n",
    "    ms_i = ms_i[::-1]\n",
    "\n",
    "    # the smaller the margin  means the classifier is more\n",
    "    # uncertain about the sample\n",
    "    return ms_i[:k, 0].astype(np.int32), ms_i[:k]\n",
    "\n",
    "#Entropy criteria\n",
    "#Return: indices of k selected samples, indices+prediction+lc value of k selected samples\n",
    "def entropy(prediction, k):\n",
    "    size = len(prediction)\n",
    "    entropy_ = - np.nansum(prediction * np.log(prediction), axis=1)\n",
    "    pred_class = np.argmax(prediction, axis=1)\n",
    "    en_i = np.column_stack((list(range(size)), pred_class, entropy_))\n",
    "\n",
    "    # Sort en_i in descending order\n",
    "    en_i = en_i[(-1 * en_i[:, 2]).argsort()]\n",
    "    return en_i[:k, 0].astype(np.int32), en_i[:k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sampling Selection\n",
    "def get_high_confidence_samples(pred_prob: np.ndarray,delta: float):\n",
    "    en_, eni = entropy(prediction=pred_prob, k=len(pred_prob))\n",
    "    hcs = eni[eni[:, 2] < delta]\n",
    "    return hcs[:, 0].astype(np.int32), hcs[:, 1].astype(np.int32)\n",
    "\n",
    "\n",
    "def get_uncertain_samples(pred_prob, k,criteria):\n",
    "    if criteria == 'lc':\n",
    "        return least_confidence(prediction=pred_prob, k=k)\n",
    "    elif criteria == 'ms':\n",
    "        return margin_sampling(prediction=pred_prob, k=k)\n",
    "    elif criteria == 'en':\n",
    "        return entropy(prediction=pred_prob, k=k)\n",
    "    else:\n",
    "        assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.24500691 0.07347462 0.18415803 0.38929432 0.10806613]\n",
      " [0.32171023 0.30209066 0.10971362 0.15663874 0.10984675]\n",
      " [0.10261614 0.36607897 0.23751959 0.15135717 0.14242813]\n",
      " [0.11703409 0.25449621 0.1832989  0.22733727 0.21783353]\n",
      " [0.19570744 0.17986119 0.03029136 0.36621777 0.22792225]\n",
      " [0.09717249 0.25241655 0.22446338 0.36633715 0.05961043]\n",
      " [0.16395701 0.24382957 0.02912987 0.2731846  0.28989896]\n",
      " [0.06470066 0.47639205 0.24711201 0.12640636 0.08538892]\n",
      " [0.02096216 0.2980948  0.33747217 0.22399674 0.11947414]\n",
      " [0.161696   0.00629839 0.43690593 0.32226396 0.07283572]\n",
      " [0.12462174 0.34582474 0.19506928 0.22834826 0.10613598]\n",
      " [0.30540454 0.17916349 0.22071668 0.02395428 0.27076102]\n",
      " [0.16348177 0.24160319 0.22250624 0.24562583 0.12678297]\n",
      " [0.12811512 0.33490139 0.27550046 0.03736756 0.22411547]\n",
      " [0.00135463 0.34137036 0.37848586 0.0414964  0.23729276]\n",
      " [0.24565155 0.04505783 0.37391404 0.16640395 0.16897263]\n",
      " [0.12704753 0.36623161 0.1825556  0.08085007 0.24331518]\n",
      " [0.10877765 0.38416541 0.00361186 0.27031838 0.23312669]\n",
      " [0.32525956 0.32990074 0.22252218 0.07342785 0.04888967]\n",
      " [0.40334273 0.12141955 0.27949168 0.05599807 0.13974797]\n",
      " [0.04589273 0.33397998 0.07929313 0.263295   0.27753917]\n",
      " [0.0650081  0.54664875 0.00170506 0.37718791 0.00945018]\n",
      " [0.30968919 0.15287049 0.11083941 0.12594505 0.30065585]\n",
      " [0.24825786 0.1454225  0.00915283 0.34837669 0.24879011]\n",
      " [0.43281984 0.03365515 0.24628953 0.18024547 0.10699001]\n",
      " [0.1482739  0.06797778 0.19347304 0.21652567 0.37374961]\n",
      " [0.3217798  0.11575469 0.22555138 0.10968693 0.2272272 ]\n",
      " [0.25119192 0.33329924 0.14157091 0.20339417 0.07054376]\n",
      " [0.26781402 0.01329264 0.19303746 0.26834731 0.25750857]\n",
      " [0.19396463 0.19625789 0.22014602 0.18437244 0.20525901]\n",
      " [0.5191954  0.07527545 0.10178386 0.17466761 0.12907768]\n",
      " [0.20262204 0.15699627 0.16958756 0.15581183 0.3149823 ]\n",
      " [0.05018229 0.10290483 0.27739311 0.06502124 0.50449854]\n",
      " [0.39300074 0.20216206 0.23321598 0.12819899 0.04342223]\n",
      " [0.06770125 0.31247358 0.11556997 0.12123191 0.38302329]\n",
      " [0.08803542 0.05158657 0.28147125 0.28822468 0.29068208]\n",
      " [0.12050276 0.3109119  0.33223613 0.1470953  0.08925391]\n",
      " [0.28614663 0.24219437 0.12156352 0.06340007 0.28669542]\n",
      " [0.11447339 0.02489333 0.37467572 0.14303398 0.34292357]\n",
      " [0.25444854 0.25683602 0.19531841 0.18333745 0.11005959]\n",
      " [0.72388467 0.05525927 0.02103893 0.03201747 0.16779966]\n",
      " [0.27269711 0.19353909 0.06661479 0.29118088 0.17596814]\n",
      " [0.1489423  0.38373618 0.21656008 0.03447694 0.2162845 ]\n",
      " [0.01734689 0.29899928 0.15416669 0.44118093 0.08830621]\n",
      " [0.2438765  0.22430457 0.10092296 0.21922328 0.21167269]\n",
      " [0.23390282 0.21646738 0.17506196 0.08477107 0.28979676]\n",
      " [0.29784314 0.21313855 0.20224976 0.09164147 0.19512708]\n",
      " [0.28082233 0.27436367 0.14467848 0.04197424 0.25816127]\n",
      " [0.15358386 0.35507614 0.09939043 0.02256868 0.36938089]\n",
      " [0.0348385  0.18787464 0.21113436 0.2812692  0.2848833 ]]\n"
     ]
    }
   ],
   "source": [
    "#Random prob to test above criterias\n",
    "prob_dist = np.random.rand(50,5)\n",
    "norm = np.reciprocal(np.reshape(np.sum(prob_dist,axis = 1),(50,1)))\n",
    "norm = np.column_stack((norm,norm,norm,norm,norm))\n",
    "prob_dist = np.multiply(prob_dist,norm)\n",
    "print(prob_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29.          2.          1.60763283]\n",
      " [12.          3.          1.58033155]\n",
      " [ 3.          1.          1.57907698]\n",
      " [44.          0.          1.57224293]\n",
      " [39.          1.          1.57024432]]\n"
     ]
    }
   ],
   "source": [
    "#Entropy test\n",
    "ic_i, ic = entropy(prob_dist,5)\n",
    "print(ic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29.          2.          0.22014602]\n",
      " [44.          0.          0.2438765 ]\n",
      " [12.          3.          0.24562583]\n",
      " [ 3.          1.          0.25449621]\n",
      " [39.          1.          0.25683602]]\n"
     ]
    }
   ],
   "source": [
    "#Least Confidence test\n",
    "ic_i, ic = least_confidence(prob_dist,5)\n",
    "print(ic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.80000000e+01  3.00000000e+00 -5.33295342e-04]\n",
      " [ 3.70000000e+01  4.00000000e+00 -5.48794433e-04]\n",
      " [ 3.90000000e+01  1.00000000e+00 -2.38748067e-03]\n",
      " [ 3.50000000e+01  4.00000000e+00 -2.45739685e-03]\n",
      " [ 4.90000000e+01  4.00000000e+00 -3.61409148e-03]]\n"
     ]
    }
   ],
   "source": [
    "#Margin Sampling test\n",
    "ic_i, ic = margin_sampling(prob_dist,5)\n",
    "print(ic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32  9 14 21 40]\n",
      "[4 2 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "#Get high confidence samples test\n",
    "en, en_i = get_high_confidence_samples(prob_dist,1.27)\n",
    "print(en)\n",
    "print(en_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "random_seed = 123\n",
    "validation_split = 0.1  \n",
    "batch_size = 16\n",
    "dataset_size = len(mnist_train)\n",
    "\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "dl_train = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, sampler=train_sampler)\n",
    "dl_test = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, sampler=valid_sampler)\n",
    "\n",
    "model = torchvision.models.resnet(pretrained=True, progress=True)\n",
    "model.fc = torch.nn.Linear(in_features=512,out_features=10,bias=True)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-f266ebb63e1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdl_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'optimizer' is not defined"
     ]
    }
   ],
   "source": [
    "for idx,(img,label) in enumerate(dl_train):\n",
    "    optimizer.zero_grad()\n",
    "    prob = model(img)\n",
    "    loss = criterion(prob,label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    #print some bookkeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ceal_learning_algorithm(du: Dataset,\n",
    "                            dl: Dataset,\n",
    "                           k: int = 1000,\n",
    "                           delta_0: float = 0.005,\n",
    "                           dr: float = 0.00033,\n",
    "                           t: int = 1,\n",
    "                           epochs: int = 10,\n",
    "                           criteria = str = 'lc',\n",
    "                           max_iter:int = 45):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
